{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "YUYNGzqlPqM3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.metrics import classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gas_turbines.csv')"
      ],
      "metadata": {
        "id": "hNeCXNPmPwcu"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "at3N90cPQ8EM",
        "outputId": "2e742a47-6566-42e6-9352-1872a890d2f5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
              "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
              "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
              "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
              "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
              "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
              "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
              "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
              "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
              "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
              "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
              "\n",
              "           CO     NOX  \n",
              "0      3.1547  82.722  \n",
              "1      3.2363  82.776  \n",
              "2      3.2012  82.468  \n",
              "3      3.1923  82.670  \n",
              "4      3.2484  82.311  \n",
              "...       ...     ...  \n",
              "15034  4.5186  79.559  \n",
              "15035  4.8470  79.917  \n",
              "15036  7.9632  90.912  \n",
              "15037  6.2494  93.227  \n",
              "15038  4.9816  92.498  \n",
              "\n",
              "[15039 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a228836-2eed-450c-8bb9-496a90598b8e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AT</th>\n",
              "      <th>AP</th>\n",
              "      <th>AH</th>\n",
              "      <th>AFDP</th>\n",
              "      <th>GTEP</th>\n",
              "      <th>TIT</th>\n",
              "      <th>TAT</th>\n",
              "      <th>TEY</th>\n",
              "      <th>CDP</th>\n",
              "      <th>CO</th>\n",
              "      <th>NOX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.8594</td>\n",
              "      <td>1007.9</td>\n",
              "      <td>96.799</td>\n",
              "      <td>3.5000</td>\n",
              "      <td>19.663</td>\n",
              "      <td>1059.2</td>\n",
              "      <td>550.00</td>\n",
              "      <td>114.70</td>\n",
              "      <td>10.605</td>\n",
              "      <td>3.1547</td>\n",
              "      <td>82.722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.7850</td>\n",
              "      <td>1008.4</td>\n",
              "      <td>97.118</td>\n",
              "      <td>3.4998</td>\n",
              "      <td>19.728</td>\n",
              "      <td>1059.3</td>\n",
              "      <td>550.00</td>\n",
              "      <td>114.72</td>\n",
              "      <td>10.598</td>\n",
              "      <td>3.2363</td>\n",
              "      <td>82.776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.8977</td>\n",
              "      <td>1008.8</td>\n",
              "      <td>95.939</td>\n",
              "      <td>3.4824</td>\n",
              "      <td>19.779</td>\n",
              "      <td>1059.4</td>\n",
              "      <td>549.87</td>\n",
              "      <td>114.71</td>\n",
              "      <td>10.601</td>\n",
              "      <td>3.2012</td>\n",
              "      <td>82.468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.0569</td>\n",
              "      <td>1009.2</td>\n",
              "      <td>95.249</td>\n",
              "      <td>3.4805</td>\n",
              "      <td>19.792</td>\n",
              "      <td>1059.6</td>\n",
              "      <td>549.99</td>\n",
              "      <td>114.72</td>\n",
              "      <td>10.606</td>\n",
              "      <td>3.1923</td>\n",
              "      <td>82.670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.3978</td>\n",
              "      <td>1009.7</td>\n",
              "      <td>95.150</td>\n",
              "      <td>3.4976</td>\n",
              "      <td>19.765</td>\n",
              "      <td>1059.7</td>\n",
              "      <td>549.98</td>\n",
              "      <td>114.72</td>\n",
              "      <td>10.612</td>\n",
              "      <td>3.2484</td>\n",
              "      <td>82.311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15034</th>\n",
              "      <td>9.0301</td>\n",
              "      <td>1005.6</td>\n",
              "      <td>98.460</td>\n",
              "      <td>3.5421</td>\n",
              "      <td>19.164</td>\n",
              "      <td>1049.7</td>\n",
              "      <td>546.21</td>\n",
              "      <td>111.61</td>\n",
              "      <td>10.400</td>\n",
              "      <td>4.5186</td>\n",
              "      <td>79.559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15035</th>\n",
              "      <td>7.8879</td>\n",
              "      <td>1005.9</td>\n",
              "      <td>99.093</td>\n",
              "      <td>3.5059</td>\n",
              "      <td>19.414</td>\n",
              "      <td>1046.3</td>\n",
              "      <td>543.22</td>\n",
              "      <td>111.78</td>\n",
              "      <td>10.433</td>\n",
              "      <td>4.8470</td>\n",
              "      <td>79.917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15036</th>\n",
              "      <td>7.2647</td>\n",
              "      <td>1006.3</td>\n",
              "      <td>99.496</td>\n",
              "      <td>3.4770</td>\n",
              "      <td>19.530</td>\n",
              "      <td>1037.7</td>\n",
              "      <td>537.32</td>\n",
              "      <td>110.19</td>\n",
              "      <td>10.483</td>\n",
              "      <td>7.9632</td>\n",
              "      <td>90.912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15037</th>\n",
              "      <td>7.0060</td>\n",
              "      <td>1006.8</td>\n",
              "      <td>99.008</td>\n",
              "      <td>3.4486</td>\n",
              "      <td>19.377</td>\n",
              "      <td>1043.2</td>\n",
              "      <td>541.24</td>\n",
              "      <td>110.74</td>\n",
              "      <td>10.533</td>\n",
              "      <td>6.2494</td>\n",
              "      <td>93.227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15038</th>\n",
              "      <td>6.9279</td>\n",
              "      <td>1007.2</td>\n",
              "      <td>97.533</td>\n",
              "      <td>3.4275</td>\n",
              "      <td>19.306</td>\n",
              "      <td>1049.9</td>\n",
              "      <td>545.85</td>\n",
              "      <td>111.58</td>\n",
              "      <td>10.583</td>\n",
              "      <td>4.9816</td>\n",
              "      <td>92.498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15039 rows Ã— 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a228836-2eed-450c-8bb9-496a90598b8e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5a228836-2eed-450c-8bb9-496a90598b8e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5a228836-2eed-450c-8bb9-496a90598b8e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c7d1326c-f547-4f34-8392-e5e40d58da3f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c7d1326c-f547-4f34-8392-e5e40d58da3f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c7d1326c-f547-4f34-8392-e5e40d58da3f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_65c9e1a6-6717-4dc3-a137-da2beeda5dd7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_65c9e1a6-6717-4dc3-a137-da2beeda5dd7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 15039,\n  \"fields\": [\n    {\n      \"column\": \"AT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.574322687875509,\n        \"min\": 0.5223,\n        \"max\": 34.929,\n        \"num_unique_values\": 12086,\n        \"samples\": [\n          8.1642,\n          5.7371,\n          9.1345\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.410760279473945,\n        \"min\": 985.85,\n        \"max\": 1034.2,\n        \"num_unique_values\": 540,\n        \"samples\": [\n          1000.6,\n          998.76,\n          1031.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.793439179623817,\n        \"min\": 30.344,\n        \"max\": 100.2,\n        \"num_unique_values\": 12637,\n        \"samples\": [\n          82.691,\n          67.866,\n          86.165\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AFDP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7601966070003089,\n        \"min\": 2.0874,\n        \"max\": 7.6106,\n        \"num_unique_values\": 11314,\n        \"samples\": [\n          5.3757,\n          4.2374,\n          2.8385\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GTEP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.1739156411582865,\n        \"min\": 17.878,\n        \"max\": 37.402,\n        \"num_unique_values\": 8234,\n        \"samples\": [\n          19.958,\n          25.172,\n          31.306\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TIT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.527805560509144,\n        \"min\": 1000.8,\n        \"max\": 1100.8,\n        \"num_unique_values\": 706,\n        \"samples\": [\n          1058.7,\n          1089.8,\n          1083.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TAT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.866802764617584,\n        \"min\": 512.45,\n        \"max\": 550.61,\n        \"num_unique_values\": 2340,\n        \"samples\": [\n          523.02,\n          548.04,\n          546.77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TEY\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.8297173034807,\n        \"min\": 100.17,\n        \"max\": 174.61,\n        \"num_unique_values\": 4207,\n        \"samples\": [\n          150.27,\n          103.79,\n          162.17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CDP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1031964742249722,\n        \"min\": 9.9044,\n        \"max\": 15.081,\n        \"num_unique_values\": 3611,\n        \"samples\": [\n          10.049,\n          14.014,\n          12.124\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CO\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.2222060306042573,\n        \"min\": 0.00038751,\n        \"max\": 44.103,\n        \"num_unique_values\": 13096,\n        \"samples\": [\n          0.20501,\n          0.40171,\n          0.57927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NOX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.470585873493848,\n        \"min\": 27.765,\n        \"max\": 119.89,\n        \"num_unique_values\": 11996,\n        \"samples\": [\n          84.471,\n          63.884,\n          63.764\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64s7mghHQ9fd",
        "outputId": "b763683c-af90-48c0-cea2-fe6c856fbd11"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AT      0\n",
              "AP      0\n",
              "AH      0\n",
              "AFDP    0\n",
              "GTEP    0\n",
              "TIT     0\n",
              "TAT     0\n",
              "TEY     0\n",
              "CDP     0\n",
              "CO      0\n",
              "NOX     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "x = df.drop(columns=['TEY'])\n",
        "y = df['TEY']"
      ],
      "metadata": {
        "id": "KIxbMvLQRPEU"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = sc.fit_transform(x)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSewnNsxStCH",
        "outputId": "0a0ca547-ac67-4171-bf83-08c110161969"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.4397781 , -0.82664395,  1.28143632, ..., -1.35733078,\n",
              "         0.53201195,  1.3878449 ],\n",
              "       [-1.44960109, -0.74864748,  1.30456402, ..., -1.36367619,\n",
              "         0.56873344,  1.39300237],\n",
              "       [-1.43472138, -0.68625031,  1.21908576, ..., -1.36095673,\n",
              "         0.5529378 ,  1.36358566],\n",
              "       ...,\n",
              "       [-1.38626659, -1.07623263,  1.47697056, ..., -1.46792219,\n",
              "         2.69592467,  2.17006209],\n",
              "       [-1.42042259, -0.99823616,  1.44159024, ..., -1.42259784,\n",
              "         1.9246834 ,  2.391165  ],\n",
              "       [-1.43073409, -0.93583899,  1.33465179, ..., -1.37727349,\n",
              "         1.35415028,  2.32153907]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.20, random_state=1)\n"
      ],
      "metadata": {
        "id": "cnNvjGRqSybF"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model\n",
        "ann = Sequential()\n",
        "\n",
        "#Add hidden layer\n",
        "ann.add(Dense(units=30,activation='relu'))\n",
        "\n",
        "#Add output layer\n",
        "ann.add(Dense(units=1))\n",
        "\n",
        "#Establish the connection between the layers\n",
        "ann.compile(optimizer = 'adam',loss='mse')\n",
        "\n",
        "#Fit the data\n",
        "ann.fit(xtrain,ytrain, epochs=100,validation_data = (xtest,ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiQWK2axSwWa",
        "outputId": "3ac31a9d-05d9-43d7-eb3b-f5a177c10968"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "376/376 [==============================] - 2s 3ms/step - loss: 16793.6836 - val_loss: 14283.1445\n",
            "Epoch 2/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 10421.1836 - val_loss: 6464.0933\n",
            "Epoch 3/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 3951.0569 - val_loss: 2188.3743\n",
            "Epoch 4/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1381.2595 - val_loss: 870.9854\n",
            "Epoch 5/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 626.8152 - val_loss: 504.8232\n",
            "Epoch 6/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 411.4996 - val_loss: 385.0249\n",
            "Epoch 7/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 321.5931 - val_loss: 312.5806\n",
            "Epoch 8/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 260.0119 - val_loss: 254.3874\n",
            "Epoch 9/100\n",
            "376/376 [==============================] - 1s 4ms/step - loss: 210.9947 - val_loss: 206.7211\n",
            "Epoch 10/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 171.9862 - val_loss: 169.3032\n",
            "Epoch 11/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 141.8302 - val_loss: 140.7403\n",
            "Epoch 12/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 118.5443 - val_loss: 119.7308\n",
            "Epoch 13/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 100.8799 - val_loss: 102.5083\n",
            "Epoch 14/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 86.6450 - val_loss: 88.6388\n",
            "Epoch 15/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 75.0112 - val_loss: 76.4082\n",
            "Epoch 16/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 65.1154 - val_loss: 66.3705\n",
            "Epoch 17/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 56.4450 - val_loss: 56.7769\n",
            "Epoch 18/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 48.3633 - val_loss: 48.2074\n",
            "Epoch 19/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 41.1079 - val_loss: 40.8910\n",
            "Epoch 20/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 35.3329 - val_loss: 35.4425\n",
            "Epoch 21/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 30.3166 - val_loss: 30.1145\n",
            "Epoch 22/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 25.7498 - val_loss: 25.4793\n",
            "Epoch 23/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 21.7228 - val_loss: 21.4881\n",
            "Epoch 24/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 18.2061 - val_loss: 18.0671\n",
            "Epoch 25/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 15.2407 - val_loss: 15.4787\n",
            "Epoch 26/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 12.7980 - val_loss: 12.9270\n",
            "Epoch 27/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 10.6259 - val_loss: 10.9272\n",
            "Epoch 28/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 8.8662 - val_loss: 9.4688\n",
            "Epoch 29/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 7.4147 - val_loss: 8.0071\n",
            "Epoch 30/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 6.2479 - val_loss: 6.9757\n",
            "Epoch 31/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 5.3219 - val_loss: 6.0177\n",
            "Epoch 32/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 4.5643 - val_loss: 5.2576\n",
            "Epoch 33/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 3.9382 - val_loss: 4.5359\n",
            "Epoch 34/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 3.4241 - val_loss: 4.0150\n",
            "Epoch 35/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 2.9926 - val_loss: 3.4666\n",
            "Epoch 36/100\n",
            "376/376 [==============================] - 1s 4ms/step - loss: 2.6341 - val_loss: 3.0705\n",
            "Epoch 37/100\n",
            "376/376 [==============================] - 1s 4ms/step - loss: 2.2925 - val_loss: 2.8066\n",
            "Epoch 38/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 2.0518 - val_loss: 2.5443\n",
            "Epoch 39/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.8264 - val_loss: 2.2146\n",
            "Epoch 40/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.6705 - val_loss: 2.0623\n",
            "Epoch 41/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.5190 - val_loss: 1.8343\n",
            "Epoch 42/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.4079 - val_loss: 1.7695\n",
            "Epoch 43/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.3136 - val_loss: 1.5978\n",
            "Epoch 44/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.2453 - val_loss: 1.4944\n",
            "Epoch 45/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.1593 - val_loss: 1.4500\n",
            "Epoch 46/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.0978 - val_loss: 1.3025\n",
            "Epoch 47/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.0395 - val_loss: 1.2363\n",
            "Epoch 48/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.9874 - val_loss: 1.1665\n",
            "Epoch 49/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.9377 - val_loss: 1.1242\n",
            "Epoch 50/100\n",
            "376/376 [==============================] - 1s 4ms/step - loss: 0.8964 - val_loss: 1.0862\n",
            "Epoch 51/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.8680 - val_loss: 1.0242\n",
            "Epoch 52/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.8274 - val_loss: 1.0139\n",
            "Epoch 53/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.7930 - val_loss: 0.9530\n",
            "Epoch 54/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.7606 - val_loss: 0.8937\n",
            "Epoch 55/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.7441 - val_loss: 0.9027\n",
            "Epoch 56/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.7185 - val_loss: 0.8238\n",
            "Epoch 57/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.6897 - val_loss: 0.7880\n",
            "Epoch 58/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.6646 - val_loss: 0.8090\n",
            "Epoch 59/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.6554 - val_loss: 0.7438\n",
            "Epoch 60/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.6360 - val_loss: 0.7038\n",
            "Epoch 61/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.6153 - val_loss: 0.6874\n",
            "Epoch 62/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.5997 - val_loss: 0.6969\n",
            "Epoch 63/100\n",
            "376/376 [==============================] - 2s 5ms/step - loss: 0.5793 - val_loss: 0.6419\n",
            "Epoch 64/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.5682 - val_loss: 0.6357\n",
            "Epoch 65/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.5545 - val_loss: 0.6321\n",
            "Epoch 66/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.5528 - val_loss: 0.6138\n",
            "Epoch 67/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.5378 - val_loss: 0.6142\n",
            "Epoch 68/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.5195 - val_loss: 0.5980\n",
            "Epoch 69/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.5091 - val_loss: 0.5742\n",
            "Epoch 70/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.5034 - val_loss: 0.5773\n",
            "Epoch 71/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4845 - val_loss: 0.5736\n",
            "Epoch 72/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4815 - val_loss: 0.5361\n",
            "Epoch 73/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4798 - val_loss: 0.5408\n",
            "Epoch 74/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4648 - val_loss: 0.5445\n",
            "Epoch 75/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4633 - val_loss: 0.5334\n",
            "Epoch 76/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.4503 - val_loss: 0.5845\n",
            "Epoch 77/100\n",
            "376/376 [==============================] - 1s 4ms/step - loss: 0.4492 - val_loss: 0.5027\n",
            "Epoch 78/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.4463 - val_loss: 0.5103\n",
            "Epoch 79/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4394 - val_loss: 0.5631\n",
            "Epoch 80/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4328 - val_loss: 0.4937\n",
            "Epoch 81/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4300 - val_loss: 0.5080\n",
            "Epoch 82/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4234 - val_loss: 0.4766\n",
            "Epoch 83/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4213 - val_loss: 0.5458\n",
            "Epoch 84/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4209 - val_loss: 0.5024\n",
            "Epoch 85/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4170 - val_loss: 0.4750\n",
            "Epoch 86/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4188 - val_loss: 0.4823\n",
            "Epoch 87/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4191 - val_loss: 0.5249\n",
            "Epoch 88/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4051 - val_loss: 0.4824\n",
            "Epoch 89/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4081 - val_loss: 0.4993\n",
            "Epoch 90/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.4048 - val_loss: 0.4578\n",
            "Epoch 91/100\n",
            "376/376 [==============================] - 1s 4ms/step - loss: 0.4023 - val_loss: 0.4948\n",
            "Epoch 92/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4704\n",
            "Epoch 93/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4070 - val_loss: 0.4519\n",
            "Epoch 94/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.4730\n",
            "Epoch 95/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.3980 - val_loss: 0.4577\n",
            "Epoch 96/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.3944 - val_loss: 0.4613\n",
            "Epoch 97/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.3960 - val_loss: 0.4695\n",
            "Epoch 98/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.3929 - val_loss: 0.4579\n",
            "Epoch 99/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.3960 - val_loss: 0.4515\n",
            "Epoch 100/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.3896 - val_loss: 0.4676\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cc789092710>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypred = ann.predict(xtest)\n",
        "ypred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeT_vFpOTaC_",
        "outputId": "385d095e-ca7d-4676-fc7b-218c01ea4a9f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[164.0271 ],\n",
              "       [139.93927],\n",
              "       [109.09482],\n",
              "       ...,\n",
              "       [156.69406],\n",
              "       [135.34174],\n",
              "       [165.07574]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytest\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37Znk-YWUoE2",
        "outputId": "3558c26f-4e37-4d2a-b78b-fc1318d1de5c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "663      164.64\n",
              "11652    138.47\n",
              "2780     109.65\n",
              "11044    102.78\n",
              "11621    113.52\n",
              "          ...  \n",
              "11268    133.59\n",
              "15020    133.78\n",
              "9097     156.73\n",
              "5375     134.76\n",
              "8158     166.12\n",
              "Name: TEY, Length: 3008, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n"
      ],
      "metadata": {
        "id": "6L8pJZBcUTD2"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(ytest,ypred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YakwoYGDUb0n",
        "outputId": "75348cf7-b1ce-424e-bfb1-cfa88f88216c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9981686000037631"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U keras-tuner\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-IG3JjCbG_S",
        "outputId": "1e030d2e-a39e-43ac-a327-a5b75de6d15d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "5VJgy1dUaXzK"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimizer_selection(hp):\n",
        "    #initialize the model\n",
        "    model = Sequential()\n",
        "    #Add hidden layer\n",
        "    model.add(Dense(units=10, activation='relu'))\n",
        "    #Add output layer\n",
        "    model.add(Dense(units=1))\n",
        "    #Optimizer selection\n",
        "    optim = hp.Choice('optimizer', values = ['sgd','adam','rmsprop'])\n",
        "    model.compile(optimizer=optim, loss = 'mse')\n",
        "    return model"
      ],
      "metadata": {
        "id": "7oizYUMkWuWR"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.RandomSearch(\n",
        "    optimizer_selection,\n",
        "    max_trials=3\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YjzsAzcZWH6",
        "outputId": "77d3357e-1673-40d2-cbd6-f4dfde7205f7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from ./untitled_project/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(xtrain,ytrain, epochs = 100, validation_data = (xtest,ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EtP4FBMnZbqG",
        "outputId": "791c8f7c-95e4-4bfb-d375-46eea8269842"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Search: Running Trial #3\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "rmsprop           |adam              |optimizer\n",
            "\n",
            "Epoch 1/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 17531.1719 - val_loss: 16622.6992\n",
            "Epoch 2/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 15432.1807 - val_loss: 14013.1318\n",
            "Epoch 3/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 12321.7227 - val_loss: 10544.6553\n",
            "Epoch 4/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 8710.2236 - val_loss: 6983.7061\n",
            "Epoch 5/100\n",
            "376/376 [==============================] - 1s 4ms/step - loss: 5469.9771 - val_loss: 4210.3071\n",
            "Epoch 6/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 3227.5393 - val_loss: 2447.4805\n",
            "Epoch 7/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1809.6581 - val_loss: 1294.2568\n",
            "Epoch 8/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 880.2415 - val_loss: 605.3002\n",
            "Epoch 9/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 433.8720 - val_loss: 361.4160\n",
            "Epoch 10/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 287.3978 - val_loss: 273.0953\n",
            "Epoch 11/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 222.5064 - val_loss: 213.5618\n",
            "Epoch 12/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 174.8391 - val_loss: 166.5803\n",
            "Epoch 13/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 137.1861 - val_loss: 130.7054\n",
            "Epoch 14/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 108.4820 - val_loss: 103.5343\n",
            "Epoch 15/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 86.1289 - val_loss: 83.0777\n",
            "Epoch 16/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 69.0575 - val_loss: 67.3247\n",
            "Epoch 17/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 56.5898 - val_loss: 55.7295\n",
            "Epoch 18/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 46.9863 - val_loss: 47.1447\n",
            "Epoch 19/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 39.7040 - val_loss: 40.4594\n",
            "Epoch 20/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 33.9854 - val_loss: 34.8898\n",
            "Epoch 21/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 28.9934 - val_loss: 30.1630\n",
            "Epoch 22/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 24.8533 - val_loss: 25.7988\n",
            "Epoch 23/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 21.3066 - val_loss: 21.8029\n",
            "Epoch 24/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 18.2208 - val_loss: 18.5339\n",
            "Epoch 25/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 15.5023 - val_loss: 15.6909\n",
            "Epoch 26/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 12.9815 - val_loss: 12.7694\n",
            "Epoch 27/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 10.5140 - val_loss: 10.0828\n",
            "Epoch 28/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 8.2390 - val_loss: 7.9049\n",
            "Epoch 29/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 6.4158 - val_loss: 6.0770\n",
            "Epoch 30/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 4.8184 - val_loss: 4.5649\n",
            "Epoch 31/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 3.6869 - val_loss: 3.5847\n",
            "Epoch 32/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 2.8612 - val_loss: 2.9709\n",
            "Epoch 33/100\n",
            "376/376 [==============================] - 1s 4ms/step - loss: 2.3383 - val_loss: 2.3820\n",
            "Epoch 34/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.9404 - val_loss: 1.9786\n",
            "Epoch 35/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.6584 - val_loss: 1.7399\n",
            "Epoch 36/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.4454 - val_loss: 1.4654\n",
            "Epoch 37/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.2489 - val_loss: 1.4199\n",
            "Epoch 38/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.0715 - val_loss: 1.0667\n",
            "Epoch 39/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.9089 - val_loss: 0.9436\n",
            "Epoch 40/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.8070 - val_loss: 0.8774\n",
            "Epoch 41/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.7431 - val_loss: 0.7985\n",
            "Epoch 42/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.6725 - val_loss: 0.7156\n",
            "Epoch 43/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.6101 - val_loss: 0.6564\n",
            "Epoch 44/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.5703 - val_loss: 0.6171\n",
            "Epoch 45/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.5464 - val_loss: 0.6002\n",
            "Epoch 46/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.5321 - val_loss: 0.5857\n",
            "Epoch 47/100\n",
            "376/376 [==============================] - 1s 4ms/step - loss: 0.5229 - val_loss: 0.5695\n",
            "Epoch 48/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.5208 - val_loss: 0.5693\n",
            "Epoch 49/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.5137 - val_loss: 0.5999\n",
            "Epoch 50/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.5112 - val_loss: 0.6102\n",
            "Epoch 51/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.5042 - val_loss: 0.5857\n",
            "Epoch 52/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.5032 - val_loss: 0.5582\n",
            "Epoch 53/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.5039 - val_loss: 0.5869\n",
            "Epoch 54/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4981 - val_loss: 0.5444\n",
            "Epoch 55/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4975 - val_loss: 0.5562\n",
            "Epoch 56/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4973 - val_loss: 0.5448\n",
            "Epoch 57/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4955 - val_loss: 0.5541\n",
            "Epoch 58/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4969 - val_loss: 0.5392\n",
            "Epoch 59/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.4934 - val_loss: 0.5356\n",
            "Epoch 60/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.4924 - val_loss: 0.5411\n",
            "Epoch 61/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.4936 - val_loss: 0.5285\n",
            "Epoch 62/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4904 - val_loss: 0.5500\n",
            "Epoch 63/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4914 - val_loss: 0.5644\n",
            "Epoch 64/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4912 - val_loss: 0.5216\n",
            "Epoch 65/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4889 - val_loss: 0.5377\n",
            "Epoch 66/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.4909 - val_loss: 0.5224\n",
            "Epoch 67/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4901 - val_loss: 0.5442\n",
            "Epoch 68/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4876 - val_loss: 0.5326\n",
            "Epoch 69/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4913 - val_loss: 0.5625\n",
            "Epoch 70/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4898 - val_loss: 0.5217\n",
            "Epoch 71/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4894 - val_loss: 0.5374\n",
            "Epoch 72/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4898 - val_loss: 0.5642\n",
            "Epoch 73/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.4881 - val_loss: 0.5671\n",
            "Epoch 74/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.4892 - val_loss: 0.5119\n",
            "Epoch 75/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.4858 - val_loss: 0.5220\n",
            "Epoch 76/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4879 - val_loss: 0.5258\n",
            "Epoch 77/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4863 - val_loss: 0.5243\n",
            "Epoch 78/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4909 - val_loss: 0.5357\n",
            "Epoch 79/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4858 - val_loss: 0.5820\n",
            "Epoch 80/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4876 - val_loss: 0.5257\n",
            "Epoch 81/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4892 - val_loss: 0.5330\n",
            "Epoch 82/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4893 - val_loss: 0.5167\n",
            "Epoch 83/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4857 - val_loss: 0.5166\n",
            "Epoch 84/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4894 - val_loss: 0.5340\n",
            "Epoch 85/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4867 - val_loss: 0.5221\n",
            "Epoch 86/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4875 - val_loss: 0.5429\n",
            "Epoch 87/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.4889 - val_loss: 0.5301\n",
            "Epoch 88/100\n",
            "376/376 [==============================] - 2s 4ms/step - loss: 0.4868 - val_loss: 0.5449\n",
            "Epoch 89/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4850 - val_loss: 0.5168\n",
            "Epoch 90/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4881 - val_loss: 0.5246\n",
            "Epoch 91/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4861 - val_loss: 0.5220\n",
            "Epoch 92/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.4851 - val_loss: 0.5582\n",
            "Epoch 93/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4862 - val_loss: 0.5683\n",
            "Epoch 94/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4845 - val_loss: 0.5141\n",
            "Epoch 95/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4855 - val_loss: 0.5284\n",
            "Epoch 96/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4862 - val_loss: 0.5259\n",
            "Epoch 97/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4889 - val_loss: 0.5256\n",
            "Epoch 98/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4871 - val_loss: 0.5283\n",
            "Epoch 99/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.4874 - val_loss: 0.6119\n",
            "Epoch 100/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.4875 - val_loss: 0.5243\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FatalTypeError",
          "evalue": "Expected the return value of HyperModel.fit() to be a single float when `objective` is left unspecified. Recevied return value: <keras.src.callbacks.History object at 0x7cc78925add0> of type <class 'keras.src.callbacks.History'>.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFatalTypeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-af441f2d2dd5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFatalError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconfig_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0;31m# Printing the stacktrace and the error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m             )\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         tuner_utils.validate_trial_results(\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner_utils.py\u001b[0m in \u001b[0;36mvalidate_trial_results\u001b[0;34m(results, objective, func_name)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     ):\n\u001b[0;32m--> 173\u001b[0;31m         raise errors.FatalTypeError(\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;34mf\"Expected the return value of {func_name} to be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;34m\"a single float when `objective` is left unspecified. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFatalTypeError\u001b[0m: Expected the return value of HyperModel.fit() to be a single float when `objective` is left unspecified. Recevied return value: <keras.src.callbacks.History object at 0x7cc78925add0> of type <class 'keras.src.callbacks.History'>."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.get_best_hyperparameters()[0].values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PzvcX4SZeRQ",
        "outputId": "dfc1e61c-7c0d-447e-e35f-ce340d34c279"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'optimizer': 'adam'}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tuner.get_best_models(num_models=1)[0]\n",
        "model.fit(xtrain,ytrain, epochs = 100, validation_data = (xtest,ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxd5_1G9Zzig",
        "outputId": "9ade951e-19e0-4993-9bcc-f56edbd41423"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 5919.4287 - val_loss: 4270.1226\n",
            "Epoch 2/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 3137.9548 - val_loss: 2314.2043\n",
            "Epoch 3/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1734.5652 - val_loss: 1344.8799\n",
            "Epoch 4/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1027.5813 - val_loss: 846.4372\n",
            "Epoch 5/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 665.6480 - val_loss: 597.6136\n",
            "Epoch 6/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 490.4513 - val_loss: 479.5578\n",
            "Epoch 7/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 404.5739 - val_loss: 415.0894\n",
            "Epoch 8/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 352.6486 - val_loss: 368.1327\n",
            "Epoch 9/100\n",
            "376/376 [==============================] - 1s 4ms/step - loss: 312.2793 - val_loss: 327.5450\n",
            "Epoch 10/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 276.1302 - val_loss: 288.1809\n",
            "Epoch 11/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 241.9076 - val_loss: 251.2286\n",
            "Epoch 12/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 209.8279 - val_loss: 216.5581\n",
            "Epoch 13/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 180.7596 - val_loss: 186.5202\n",
            "Epoch 14/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 155.0744 - val_loss: 160.0622\n",
            "Epoch 15/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 132.6963 - val_loss: 137.4346\n",
            "Epoch 16/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 113.9916 - val_loss: 118.9600\n",
            "Epoch 17/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 98.5373 - val_loss: 103.3842\n",
            "Epoch 18/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 85.7398 - val_loss: 90.8250\n",
            "Epoch 19/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 75.4720 - val_loss: 81.0745\n",
            "Epoch 20/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 67.2360 - val_loss: 71.9060\n",
            "Epoch 21/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 59.9467 - val_loss: 64.5578\n",
            "Epoch 22/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 53.5821 - val_loss: 57.2479\n",
            "Epoch 23/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 47.6524 - val_loss: 50.7515\n",
            "Epoch 24/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 42.2575 - val_loss: 45.0913\n",
            "Epoch 25/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 37.2744 - val_loss: 39.6605\n",
            "Epoch 26/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 32.7036 - val_loss: 35.0147\n",
            "Epoch 27/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 28.5562 - val_loss: 30.5863\n",
            "Epoch 28/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 24.9642 - val_loss: 26.9719\n",
            "Epoch 29/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 21.8283 - val_loss: 23.7921\n",
            "Epoch 30/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 19.0859 - val_loss: 21.1050\n",
            "Epoch 31/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 16.7049 - val_loss: 18.5184\n",
            "Epoch 32/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 14.7185 - val_loss: 16.3334\n",
            "Epoch 33/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 12.9623 - val_loss: 14.4186\n",
            "Epoch 34/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 11.4898 - val_loss: 12.9349\n",
            "Epoch 35/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 10.2298 - val_loss: 11.6451\n",
            "Epoch 36/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 9.2233 - val_loss: 10.4399\n",
            "Epoch 37/100\n",
            "376/376 [==============================] - 1s 4ms/step - loss: 8.3126 - val_loss: 9.3651\n",
            "Epoch 38/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 7.5306 - val_loss: 8.4818\n",
            "Epoch 39/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 6.8164 - val_loss: 7.7269\n",
            "Epoch 40/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 6.1460 - val_loss: 6.9344\n",
            "Epoch 41/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 5.5470 - val_loss: 6.2181\n",
            "Epoch 42/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 4.9851 - val_loss: 5.6047\n",
            "Epoch 43/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 4.4931 - val_loss: 5.0397\n",
            "Epoch 44/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 4.0726 - val_loss: 4.7573\n",
            "Epoch 45/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 3.7245 - val_loss: 4.2516\n",
            "Epoch 46/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 3.4401 - val_loss: 3.9171\n",
            "Epoch 47/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 3.1729 - val_loss: 3.6585\n",
            "Epoch 48/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 2.9482 - val_loss: 3.3690\n",
            "Epoch 49/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 2.7466 - val_loss: 3.1426\n",
            "Epoch 50/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 2.5760 - val_loss: 2.9236\n",
            "Epoch 51/100\n",
            "376/376 [==============================] - 1s 4ms/step - loss: 2.3925 - val_loss: 2.7403\n",
            "Epoch 52/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 2.2408 - val_loss: 2.5839\n",
            "Epoch 53/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 2.1035 - val_loss: 2.3706\n",
            "Epoch 54/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.9778 - val_loss: 2.2333\n",
            "Epoch 55/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 1.8588 - val_loss: 2.0892\n",
            "Epoch 56/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.7702 - val_loss: 2.0741\n",
            "Epoch 57/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.6842 - val_loss: 1.8825\n",
            "Epoch 58/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.5903 - val_loss: 1.8012\n",
            "Epoch 59/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.5152 - val_loss: 1.6998\n",
            "Epoch 60/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.4504 - val_loss: 1.6193\n",
            "Epoch 61/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.3948 - val_loss: 1.5482\n",
            "Epoch 62/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.3326 - val_loss: 1.5065\n",
            "Epoch 63/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 1.2765 - val_loss: 1.4017\n",
            "Epoch 64/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 1.2269 - val_loss: 1.3624\n",
            "Epoch 65/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 1.1844 - val_loss: 1.3490\n",
            "Epoch 66/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.1473 - val_loss: 1.3283\n",
            "Epoch 67/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.1086 - val_loss: 1.2999\n",
            "Epoch 68/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.0816 - val_loss: 1.2120\n",
            "Epoch 69/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.0493 - val_loss: 1.1548\n",
            "Epoch 70/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 1.0189 - val_loss: 1.1666\n",
            "Epoch 71/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 1.0032 - val_loss: 1.0883\n",
            "Epoch 72/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.9788 - val_loss: 1.0612\n",
            "Epoch 73/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.9561 - val_loss: 1.0843\n",
            "Epoch 74/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.9446 - val_loss: 1.0171\n",
            "Epoch 75/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.9178 - val_loss: 1.0059\n",
            "Epoch 76/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.8995 - val_loss: 0.9590\n",
            "Epoch 77/100\n",
            "376/376 [==============================] - 1s 4ms/step - loss: 0.8831 - val_loss: 0.9438\n",
            "Epoch 78/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.8700 - val_loss: 0.9561\n",
            "Epoch 79/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.8537 - val_loss: 0.9233\n",
            "Epoch 80/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.8425 - val_loss: 0.9347\n",
            "Epoch 81/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.8277 - val_loss: 0.9250\n",
            "Epoch 82/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.8045 - val_loss: 0.8882\n",
            "Epoch 83/100\n",
            "376/376 [==============================] - 1s 4ms/step - loss: 0.7852 - val_loss: 0.8610\n",
            "Epoch 84/100\n",
            "376/376 [==============================] - 2s 4ms/step - loss: 0.7675 - val_loss: 0.8469\n",
            "Epoch 85/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.7631 - val_loss: 0.8318\n",
            "Epoch 86/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.7428 - val_loss: 0.8127\n",
            "Epoch 87/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.7322 - val_loss: 0.8051\n",
            "Epoch 88/100\n",
            "376/376 [==============================] - 1s 4ms/step - loss: 0.7157 - val_loss: 0.8096\n",
            "Epoch 89/100\n",
            "376/376 [==============================] - 1s 3ms/step - loss: 0.7099 - val_loss: 0.8041\n",
            "Epoch 90/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.7005 - val_loss: 0.7861\n",
            "Epoch 91/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.6953 - val_loss: 0.7982\n",
            "Epoch 92/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.6855 - val_loss: 0.7757\n",
            "Epoch 93/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.6839 - val_loss: 0.7707\n",
            "Epoch 94/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.6688 - val_loss: 0.7846\n",
            "Epoch 95/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.6689 - val_loss: 0.7484\n",
            "Epoch 96/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.6576 - val_loss: 0.7478\n",
            "Epoch 97/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.6543 - val_loss: 0.7605\n",
            "Epoch 98/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.6442 - val_loss: 0.7254\n",
            "Epoch 99/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.6487 - val_loss: 0.7200\n",
            "Epoch 100/100\n",
            "376/376 [==============================] - 1s 2ms/step - loss: 0.6350 - val_loss: 0.7262\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cc77ae2a980>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(xtrain,ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9dAFk4PZ2gB",
        "outputId": "0af6630a-f35d-4131-f169-1d789e644ada"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "376/376 [==============================] - 1s 1ms/step - loss: 0.6370\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6369842290878296"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UJEsVracbWAB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}